{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "926b1041-c407-4321-bb2e-93807f26ecf9",
   "metadata": {},
   "source": [
    "# 1. LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bdd8e698-ee7d-4fb2-b8f0-4d51646bfb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re  # Importamos para manejar expresiones regulares\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789430bf-1d3e-4487-9b40-ffee93aaf279",
   "metadata": {},
   "source": [
    "# 2. LOCAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e841950e-1c46-443d-b450-de0a941f5fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables globales\n",
    "#Nombre del dataframe final\n",
    "Regimen = \"NCEPSC25\"\n",
    "#Regimen = \"NSEPS025\"\n",
    "nombre_merged = \"neg_all_2024\"\n",
    "# Definir la ruta donde se guardará el archivo Excel basado en la variable nombre_merged\n",
    "output_name = f\"{nombre_merged}.xlsx\"\n",
    "output_path = os.path.join(r\"C:/Users/crist/OneDrive - Corporación Universitaria Remington UNIREMINGTON/Estudio/Ciencia de datos/Lumethik/eps-data-solutions/data/raw/Procesos BDUA/Contributivo/Negados/Files since 2018 until 2024/\", output_name)\n",
    "#output_path = os.path.join(r\"C:\\Users\\carlo\\Downloads\", output_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504f53f2-6394-48b1-924c-d3bfe37639cc",
   "metadata": {},
   "source": [
    "# 3. READING OF FOLDER WITH DATA NEGADOS OR VALIDADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b9caee-5059-4079-9d07-02ba1cfcd495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_ruta_carpeta():\n",
    "    folder_path = input('Por favor, ingresa la ruta de la carpeta (incluyendo las comillas si están presentes): ')\n",
    "    folder_path = folder_path.strip('\"').replace(\"\\\\\", \"/\")\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"La ruta {folder_path} no existe.\")\n",
    "        return None\n",
    "    return folder_path\n",
    "\n",
    "def cargar_archivos_a_dataframe(folder_path, extensiones=[\".NEG\", \".VAL\"], sep=\",\", encoding=\"latin-1\"):\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"La ruta {folder_path} no es válida.\")\n",
    "        return {}\n",
    "    \n",
    "    dataframes = {}\n",
    "    for ext in extensiones:\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith(ext):\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                try:\n",
    "                    df = pd.read_csv(file_path, sep=sep, encoding=encoding, header=None)\n",
    "                    df.columns = [f\"col_{j+1}\" for j in range(df.shape[1])]\n",
    "                    \n",
    "                    nombre_base = os.path.splitext(filename)[0]  # Nombre sin extensión\n",
    "                    nombre_base = nombre_base.replace(Regimen, \"\")  # Eliminar \"NSEPS025\" del nombre\n",
    "                    clave = f\"df_{nombre_base}\"  # Clave personalizada\n",
    "                    dataframes[clave] = df\n",
    "                    print(f\"Archivo {filename} cargado como {clave}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"No se pudo leer el archivo {filename}: {e}\")\n",
    "    \n",
    "    total_df = len(dataframes)\n",
    "    print(f\"\\nSe crearon {total_df} DataFrames en total.\")\n",
    "    \n",
    "    if not dataframes:\n",
    "        print(\"No se cargaron archivos en la carpeta especificada.\")\n",
    "    return dataframes\n",
    "\n",
    "def agregar_nombre_a_dataframes(dataframes):\n",
    "    \"\"\"\n",
    "    Agrega una columna adicional a cada DataFrame con su nombre (clave del diccionario).\n",
    "    \"\"\"\n",
    "    for name, df in dataframes.items():\n",
    "        df[\"nombre_dataframe\"] = name  # Agrega una columna con el nombre del DataFrame\n",
    "    print(\"Se agregó la columna 'nombre_dataframe' a todos los DataFrames.\")\n",
    "\n",
    "def mostrar_primeras_filas(dataframes):\n",
    "    for name, df in dataframes.items():\n",
    "        print(f\"Primeras filas de {name}:\")\n",
    "        print(df.head())\n",
    "        print(\"\\n---\\n\")\n",
    "        # Puedes quitar el \"break\" si deseas mostrar todos los DataFrames\n",
    "        break\n",
    "\n",
    "# Ejecución del script\n",
    "ruta = obtener_ruta_carpeta()\n",
    "if ruta:\n",
    "    # Incluye las extensiones .NEG y .VAL\n",
    "    dataframes = cargar_archivos_a_dataframe(ruta, extensiones=[\".NEG\", \".VAL\"])\n",
    "    if dataframes:\n",
    "        # Agregar el nombre del DataFrame como columna\n",
    "        agregar_nombre_a_dataframes(dataframes)\n",
    "        # Mostrar las primeras filas de los DataFrames\n",
    "        mostrar_primeras_filas(dataframes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d04365f-26ba-47a8-8a5b-90321f60776d",
   "metadata": {},
   "source": [
    "Revisando las dimenciones de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3316c4b7-eafc-4652-84ca-908418d3b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si df_1 está en el diccionario 'dataframes', lo puedes acceder así:\n",
    "\n",
    "#dataframes['df_22112019'].head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11893e78-333d-459e-9b4a-c57ebdfe436d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3.1 Searching the shape of all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87efeeba-f798-4846-8235-49d1907d6b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Name  Row  Cols')\n",
    "\n",
    "# Lista para almacenar la cantidad de filas\n",
    "row_counts = []\n",
    "\n",
    "# Recorremos los DataFrames en el diccionario\n",
    "for name, df in dataframes.items():\n",
    "    rows, cols = df.shape\n",
    "    row_counts.append(rows)  # Añadimos la cantidad de filas a la lista\n",
    "    print(f\"{name}: {rows}  {cols}\")\n",
    "\n",
    "# Calculamos el total de filas\n",
    "total_rows = sum(row_counts)\n",
    "print(f\"\\nTotal de registros en todos los DataFrames: {total_rows}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b013fb86-38f3-485b-864f-0e7b961b4000",
   "metadata": {},
   "source": [
    "# 4. Creating the original Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182a1b4f-d774-419c-b88b-4fd0d9ba899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el número de columnas deseadas\n",
    "num_columnas = 22\n",
    "\n",
    "# Asegurar que todos los DataFrames tengan exactamente el mismo número de columnas\n",
    "dataframes_alineados = {name: df.iloc[:, :num_columnas] for name, df in dataframes.items()}\n",
    "\n",
    "# Definir un nombre fijo para el DataFrame combinado\n",
    "#nombre_merged = \"merged_meses\"\n",
    "\n",
    "# Combinar todos los DataFrames alineados, sin crear nuevas columnas\n",
    "globals()[nombre_merged] = pd.concat(dataframes_alineados.values(), axis=0, ignore_index=True)\n",
    "\n",
    "# Mostrar el shape del DataFrame combinado\n",
    "print(f\"Shape del DataFrame '{nombre_merged}': {globals()[nombre_merged].shape}\")\n",
    "\n",
    "# Verificar las primeras filas\n",
    "print(f\"Primeras 5 filas del DataFrame '{nombre_merged}':\")\n",
    "print(globals()[nombre_merged].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adaf42e-1204-464f-a42c-c5257d3ad18a",
   "metadata": {},
   "source": [
    "## 4.1 Checking the Merged's Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5952f74-cd8f-40cf-98fc-4bc809e40306",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(globals()[nombre_merged].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e6fc19-f11f-4ce4-8726-7991c0f41ef0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4.2 Cleaning the Merged's colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1dd52a-c6b5-49ac-9229-bb9421ddc1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona las columnas que deseas mantener\n",
    "globals()[nombre_merged] = globals()[nombre_merged][['col_2', 'col_3','col_4','col_9', 'col_10', 'col_11', 'col_12', 'col_13','nombre_dataframe','col_21']]\n",
    "#union_2019 = union_2019[['col_2', 'col_3','col_8','col_9', 'col_10', 'col_11', 'col_12', 'col_13', 'col_21']]\n",
    "# Verifica el resultado\n",
    "print(globals()[nombre_merged].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50b40c1-e761-4f60-83f1-e755d8f825c7",
   "metadata": {},
   "source": [
    "## 4.3 Renaming column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddbfc2c-f526-4d60-b771-0d686f55bb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtiene la cantidad de columnas en el DataFrame\n",
    "num_columns = globals()[nombre_merged].shape[1]\n",
    "\n",
    "# Genera nuevos nombres de columnas: 'colum1', 'colum2', ..., 'columnN'\n",
    "new_columns = [f'colum{i+1}' for i in range(num_columns)]\n",
    "\n",
    "# Asigna los nuevos nombres de columnas al DataFrame\n",
    "globals()[nombre_merged].columns = new_columns\n",
    "\n",
    "# Verifica el resultado\n",
    "print(globals()[nombre_merged].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ad6470-ddf6-4886-bae2-8418b42e837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[nombre_merged].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ef8d7b-afae-4b65-8cd8-035da21b5c5a",
   "metadata": {},
   "source": [
    "## 4.4 Looking for the column with df_ and converting to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b562d8-46b0-40e7-90a2-8700fe16436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import re  # Importamos para manejar expresiones regulares\n",
    "\n",
    "# Procesamos directamente el DataFrame en globals()\n",
    "for column in globals()[nombre_merged].columns:\n",
    "    # Modificamos las celdas de cada columna según el patrón\n",
    "    globals()[nombre_merged][column] = globals()[nombre_merged][column].astype(str).apply(\n",
    "        lambda x: re.sub(r'^df_(\\d{2})(\\d{2})(\\d{4})$', r'\\1/\\2/\\3', x) \n",
    "        if 'df_' in x else x\n",
    "    )\n",
    "\n",
    "# Confirmamos que la transformación se realizó\n",
    "print(f\"Transformación realizada directamente en el DataFrame: {nombre_merged}\")\n",
    "print(globals()[nombre_merged].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865d1ce1-badb-4811-8431-ec8786257490",
   "metadata": {},
   "source": [
    "## 4.5 Change type of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8746a305-3ada-4c4e-b954-0db5496437e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recorremos cada columna del DataFrame\n",
    "for column in globals()[nombre_merged].columns:\n",
    "    print(f\"Procesando columna: {column}\")  # Mostrar la columna actual\n",
    "    \n",
    "    if column == \"colum3\":\n",
    "        # Convertir la columna 'colum3' directamente a string\n",
    "        print(f\"Convirtiendo la columna '{column}' a string\")\n",
    "        globals()[nombre_merged][column] = globals()[nombre_merged][column].astype(str)\n",
    "        continue  # Pasar a la siguiente columna después de procesar 'colum3'\n",
    "    \n",
    "    # Convertir a entero si todos los valores son numéricos\n",
    "    if globals()[nombre_merged][column].apply(lambda x: str(x).isdigit()).all():\n",
    "        print(f\"Intentando convertir la columna '{column}' a entero\")\n",
    "        globals()[nombre_merged][column] = globals()[nombre_merged][column].astype(int)\n",
    "    \n",
    "    # Convertir a string con formato DD/MM/YYYY si los valores están en formato de fecha\n",
    "    else:\n",
    "        try:\n",
    "            print(f\"Intentando convertir la columna '{column}' a formato de fecha\")\n",
    "            # Convertir a datetime primero\n",
    "            globals()[nombre_merged][column] = pd.to_datetime(\n",
    "                globals()[nombre_merged][column], format='%d/%m/%Y', errors='raise'\n",
    "            )\n",
    "            # Convertir a string con formato DD/MM/YYYY\n",
    "            globals()[nombre_merged][column] = globals()[nombre_merged][column].dt.strftime('%d/%m/%Y')\n",
    "        except Exception as e:\n",
    "            print(f\"No se pudo convertir la columna '{column}' a fecha: {e}\")\n",
    "            pass  # Si no es fecha, se deja igual\n",
    "\n",
    "print(f\"Conversión de tipos completada en el DataFrame: {nombre_merged}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85fec53-f18e-4894-96ef-2d02717155cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[nombre_merged].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd72d069-04ec-46b8-adf0-e5f15c94c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[nombre_merged].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdf3c7e-67aa-4e11-802a-1a9779cf8adc",
   "metadata": {},
   "source": [
    "## 4.6 Renaming names Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8795dbe8-6c4e-4627-a900-43287c8605c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar las columnas\n",
    "globals()[nombre_merged].columns = ['cod_reg', 'tip_doc', 'doc', 'fech_nac', 'dep', 'mun', 'nov', 'fech_nov', 'fecha_rep', 'observs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2383ada-31cc-4975-b319-4cf7f718518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[nombre_merged].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a6cf72-9bd0-4b3a-96e3-63f76391bed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[nombre_merged].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d17aa91-44bf-477d-bd43-af92afefaa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[nombre_merged].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6012103b",
   "metadata": {},
   "source": [
    "# 4.7 Counting Glosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0afb88e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir una función para contar el número de glosas en un registro\n",
    "def count_glosas(observs):\n",
    "    # Asegúrate de trabajar con cadenas\n",
    "    if isinstance(observs, str):\n",
    "        return len(re.findall(r'GN\\d{4}', observs))\n",
    "    # Si no es una cadena, devolver 0\n",
    "    return 0\n",
    "\n",
    "# Aplicar la función a la columna 'observs' y crear la nueva columna 'No_Glosas'\n",
    "globals()[nombre_merged][\"No_Glosas\"] = globals()[nombre_merged][\"observs\"].apply(count_glosas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dea5bf3-d929-44a9-9c75-7d5e227ace18",
   "metadata": {},
   "source": [
    "## 4.7.1 Divide las glosas que estan concatenadas en 1 solo registro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf3ca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Crear nueva columna separando por punto y coma\n",
    "globals()[nombre_merged]['observaciones_split'] = globals()[nombre_merged]['observs'].str.split(';')\n",
    "\n",
    "# 2. Usar explode para crear una fila por cada elemento\n",
    "df_resultado = globals()[nombre_merged].explode('observaciones_split')\n",
    "\n",
    "# 3. Resetear el índice\n",
    "df_resultado = df_resultado.reset_index(drop=True)\n",
    "\n",
    "# 4. Guardar el resultado\n",
    "globals()[nombre_merged] = df_resultado\n",
    "\n",
    "# Mostrar resultado\n",
    "print(\"\\nPrimeras 10 filas del DataFrame procesado:\")\n",
    "print(df_resultado.head(10))\n",
    "\n",
    "# Mostrar conteo de filas\n",
    "print(f\"\\nTotal de filas antes de separar: {len(globals()[nombre_merged])}\")\n",
    "print(f\"Total de filas después de separar: {len(df_resultado)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fb2c6a-e435-4f28-9663-3ccf141d1834",
   "metadata": {},
   "source": [
    "## 4.7.2 Creating new files for every glosa per User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2bb6d6-406b-4d01-800d-8212a8a95462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 1. Crear la nueva columna para las glosas\n",
    "globals()[nombre_merged]['obs_glos'] = ''\n",
    "\n",
    "# 2. Función para separar GN y glosa\n",
    "def separar_gn_glosa(texto):\n",
    "    if isinstance(texto, str):\n",
    "        # Buscar específicamente GN seguido de exactamente 4 dígitos\n",
    "        match = re.match(r'(GN\\d{4})(.*)', texto.strip())\n",
    "        if match:\n",
    "            return match.group(1), match.group(2).strip()\n",
    "    return texto, ''\n",
    "\n",
    "# 3. Aplicar la separación\n",
    "for idx, row in globals()[nombre_merged].iterrows():\n",
    "    gn, glosa = separar_gn_glosa(row['observaciones_split'])\n",
    "    globals()[nombre_merged].at[idx, 'observaciones_split'] = gn\n",
    "    globals()[nombre_merged].at[idx, 'obs_glos'] = glosa\n",
    "\n",
    "# 4. Mostrar el resultado\n",
    "print(\"\\nPrimeras 10 filas después de separar GN y glosas:\")\n",
    "print(globals()[nombre_merged][['observaciones_split', 'obs_glos']].head(10))\n",
    "\n",
    "# 5. Mostrar algunos ejemplos de las separaciones realizadas\n",
    "print(\"\\nEjemplos de separaciones realizadas:\")\n",
    "muestra = globals()[nombre_merged][['observaciones_split', 'obs_glos']].sample(5)\n",
    "print(muestra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660be9e5-a09e-444c-89b8-cd1387684101",
   "metadata": {},
   "source": [
    "## 4.7.2 Deleting Nan dates in observaciones_split column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca5dc64-1f8c-43d8-a9df-a0c8972ed274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar valores vacíos y espacios en blanco\n",
    "df_resultado = globals()[nombre_merged]\n",
    "df_resultado = df_resultado[df_resultado['observaciones_split'].notna()]  # Elimina NaN\n",
    "df_resultado = df_resultado[df_resultado['observaciones_split'].str.strip() != '']  # Elimina strings vacíos o solo espacios\n",
    "\n",
    "# Guardar el resultado limpio\n",
    "globals()[nombre_merged] = df_resultado\n",
    "\n",
    "# Mostrar resultado\n",
    "print(\"\\nPrimeras 5 filas después de limpiar:\")\n",
    "print(df_resultado.head())\n",
    "\n",
    "print(f\"\\nTotal de filas después de limpiar: {len(df_resultado)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2704203b-8cb3-4e00-aa3e-6e22a3990708",
   "metadata": {},
   "source": [
    "# 5. DOWNLADING FENITIVE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f20b50-cb2a-44fb-a1b7-a8f98a2bc01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame como un archivo Excel\n",
    "globals()[nombre_merged].to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"El archivo se ha guardado correctamente en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ba6f36-1e61-45ba-91f1-11fba321c5fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 6. Notes\n",
    "\n",
    "Colega hasta aqui se exporta un archivo en formato xlx, esta pendiente que sumerced agregue el paso de tratamiento para la columna de observaciones, la idea seria que lo numere y lo agregue aqui. por otra parte si quiere optimizar este codigo es libre de hacerlo, estoy abierto a cualquier sugerencia para mejorar. Gracias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
